# FUDAN_DATA620004 HW
## HW1 基于numpy的两层神经网络
本次作业主要使用ipynb写成。下面是其中各个组件以及简要介绍（如有必要），并将与作业中的要求相关的部分做了加粗处理。
代码的主要组成部分有：

0. 导入一系列相关的包
   
   该部分主要是导包以及导入数据集，在这里使用了torchvision来导入mnist数据集，并将train set重新划分为了用于训练的train set和用于调整超参数的val set，test set保持不变。

1. 通过numpy实现**线性层、激活函数层、Softmax层**
   
   通过numpy实现了**线性层**、**激活函数层**、**loss函数**的基础结构，以及相对应的前向传播、**反向传播**与**梯度**的计算。

2. 实现带**学习率衰减**的**SGD**
   
3. 实现**L2正则化**
   
4. 实现**模型保存**
   
5. **参数查找**
   
   1. 模型封装

      在内部实现了train set以及val set上每个iteration下loss（基于随机选取的某一个样本进行计算）的保存与返回。同时出于节约计算考量，为返回val上的acc曲线，每100个iteration在整个val set上计算一次acc。

   2. 网格搜参
   
      超参数：**学习率，隐藏层大小，正则化强度**

      通过val set上的acc作为模型优劣的评价指标对模型进行选取。接着对所选的最优模型的效果进行可视化，包括**训练和测试的loss曲线，测试的accuracy曲线**

   3. 保存模型

6. 读取模型
   
   在内部首先实现了模型结构的读取。根据结构创建了网络，并通过指定的路径读取了模型参数。进而实现了模型结构输出、模型参数可视化，以及对test set的预测结果。
   

**如何训练：**

运行组件0-5。**注意，在运行组件5时要指定模型的保存路径。**

输入：模型的保存路径

输出：
1. 网格搜索得到的最优模型的性能可视化。（训练和测试的loss曲线，测试的accuracy曲线）
2. 最优的模型

**如何测试：**
运行组件0-1、组件6。**模型的保存路径要与前面的相同。**

输入：模型的保存路径

输出：
1. 模型参数可视化
2. 预测结果

## 代码以及相关文件详见HW1文件夹